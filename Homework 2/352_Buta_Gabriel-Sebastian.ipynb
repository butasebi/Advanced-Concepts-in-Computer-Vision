{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de94425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import pdb\n",
    "import pickle\n",
    "import ntpath\n",
    "from copy import deepcopy\n",
    "import timeit\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import pdb\n",
    "import ntpath\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808fa65a-78f4-4f9c-9435-cc40d62aa627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1118c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The paths the user is required to modify in order to predict\n",
    "saved_model_path = \"./model_91.73\"\n",
    "saved_model_task2_andy_path = \"./model_andy\"\n",
    "saved_model_task2_louie_path = \"./model_louie\"\n",
    "saved_model_task2_ora_path = \"./model_ora\"\n",
    "saved_model_task2_tommy_path = \"./model_tommy\"\n",
    "\n",
    "task1_predictions_save_path = \"./Task1/\"\n",
    "task2_predictions_save_path = \"./Task2/\"\n",
    "\n",
    "dataset_test_path = \"./Validare\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d22e06",
   "metadata": {},
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058c3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_examples = 10000 #number of positive examples per folder of input (write 1e9 for taking the hole folder)\n",
    "\n",
    "#mandatory that nr_negatives >= nr_examples\n",
    "nr_negatives = 22 #nr negatives per image\n",
    "box_size = 96\n",
    "from_saved_model = True # True is we want to use the model saved at saved_model_path, False if we want to generate it this run\n",
    "\n",
    "from_saved_model_task2 = True # True is we want to use the saved models for task2, False if we want to generate them\n",
    "\n",
    "\n",
    "# Paths used to train the model\n",
    "\n",
    "do_we_train_the_model = False #True if we want to train the model\n",
    "\n",
    "\n",
    "# Paths below are used only when training (you can ignore them if you don't train the model)\n",
    "dataset_save_path = \"./data/Savefile/\"\n",
    "\n",
    "dataset_andy_path = \"./data/andy/\"\n",
    "dataset_andy_truth_path = \"./data/andy_annotations.txt\"\n",
    "\n",
    "dataset_louie_path = \"./data/louie/\"\n",
    "dataset_louie_truth_path = \"./data/louie_annotations.txt\"\n",
    "\n",
    "dataset_ora_path = \"./data/ora/\"\n",
    "dataset_ora_truth_path = \"./data/ora_annotations.txt\"\n",
    "\n",
    "dataset_tommy_path = \"./data/tommy/\"\n",
    "dataset_tommy_truth_path = \"./data/tommy_annotations.txt\"\n",
    "\n",
    "valid_faces_character = []\n",
    "\n",
    "def get_faces(character, nr_examples, images_path, images_annotations_path):\n",
    "    positive_descriptors = []\n",
    "    global valid_faces_character\n",
    "    \n",
    "    f = open(images_annotations_path, \"r\")\n",
    "\n",
    "    ct = 0\n",
    "    for line in f:\n",
    "        aux = line.split()\n",
    "        aux = [aux[0], int(aux[1]), int(aux[2]), int(aux[3]), int(aux[4]), aux[5]]\n",
    "        \n",
    "        print(character + \": \" + str(ct + 1))\n",
    "\n",
    "        if ct == nr_examples:\n",
    "            break\n",
    "        ct = ct + 1\n",
    "\n",
    "        image = cv.imread(images_path + aux[0])\n",
    "        if aux[4] - aux[2] > aux[3] - aux[1]:\n",
    "            image = image[aux[2] : aux[4], aux[1] : aux[1] + (aux[4] - aux[2])]\n",
    "        else:\n",
    "            image = image[aux[2] : aux[2] + (aux[3] - aux[1]), aux[1] : aux[3]]\n",
    "\n",
    "        global box_size\n",
    "    \n",
    "        image = cv.resize(image, (box_size, box_size))\n",
    "\n",
    "        positive_descriptors.append(image)\n",
    "        positive_descriptors.append(np.fliplr(image))\n",
    "        \n",
    "        valid_faces_character.append(aux[5])\n",
    "        valid_faces_character.append(aux[5])\n",
    "\n",
    "    positive_descriptors = np.array(positive_descriptors)\n",
    "    return positive_descriptors\n",
    "        \n",
    "def four_digits_jpg(nr):\n",
    "    if nr >= 0 and nr <= 9:\n",
    "        return \"000\" + str(nr) + \".jpg\"\n",
    "    if nr >= 10 and nr <= 99:\n",
    "        return \"00\" + str(nr) + \".jpg\"\n",
    "    if nr >= 100 and nr <= 999:\n",
    "        return \"0\" + str(nr) + \".jpg\"\n",
    "    return str(nr) + \".jpg\"\n",
    "\n",
    "def intersection(bbox_a, bbox_b):\n",
    "    x_a = max(bbox_a[0], bbox_b[0])\n",
    "    y_a = max(bbox_a[1], bbox_b[1])\n",
    "    x_b = min(bbox_a[2], bbox_b[2])\n",
    "    y_b = min(bbox_a[3], bbox_b[3])\n",
    "\n",
    "    inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "\n",
    "    return inter_area > 0\n",
    "    \n",
    "\n",
    "def find_neg_example(list_of_faces, files, len_f, i, photo_name = None, indices = None, wrong_search_filenames = None):\n",
    "    img = cv.imread(files[i])\n",
    "    num_rows = img.shape[0]\n",
    "    num_cols = img.shape[1]\n",
    "    ct = 0\n",
    "    while True:\n",
    "        ct = ct + 1\n",
    "        if ct == 100:\n",
    "            break\n",
    "        x = np.random.randint(0, num_cols - box_size)\n",
    "        y = np.random.randint(0, num_rows - box_size)\n",
    "\n",
    "        ok = True\n",
    "        if photo_name != None:\n",
    "            for face in list_of_faces[photo_name]:\n",
    "                if intersection(face, [x, y, x + box_size, y + box_size]):\n",
    "                    ok = False\n",
    "                    break\n",
    "        else: \n",
    "            for face in list_of_faces[four_digits_jpg(i + 1)]:\n",
    "                if intersection(face, [x, y, x + box_size, y + box_size]):\n",
    "                    ok = False\n",
    "                    break\n",
    "\n",
    "        if ok:\n",
    "            break\n",
    "    if ct == 100:\n",
    "        if photo_name != None:\n",
    "            aux = np.random.randint(0, len_f - 1)\n",
    "            return find_neg_example(list_of_faces, files, len_f, aux, wrong_search_filenames[int(indices[aux])], indices, wrong_search_filenames)\n",
    "        return find_neg_example(list_of_faces, files, len_f, np.random.randint(0, len_f - 1))\n",
    "    return x, y\n",
    "    \n",
    "def get_non_faces(character, nr_examples, nr_negatives, images_path, images_annotations_path):\n",
    "    negative_descriptors = []\n",
    "    num_negative_per_image = nr_negatives\n",
    "    \n",
    "    f = open(images_annotations_path, \"r\")\n",
    "    ct = 0\n",
    "    list_of_faces = {}\n",
    "    for line in f:\n",
    "        aux = line.split()\n",
    "        aux = [aux[0], int(aux[1]), int(aux[2]), int(aux[3]), int(aux[4]), aux[5]]\n",
    "        \n",
    "        if aux[0] == four_digits_jpg(nr_examples + 1):\n",
    "            break\n",
    "        if aux[0] in list_of_faces:\n",
    "            list_of_faces[aux[0]].append([aux[1], aux[2], aux[3], aux[4]])\n",
    "        else:\n",
    "            list_of_faces[aux[0]] = [[aux[1], aux[2], aux[3], aux[4]]]\n",
    "    \n",
    "    files = glob.glob(images_path + \"*.jpg\")\n",
    "    num_images = len(files)\n",
    "        \n",
    "    for i in range(num_images):\n",
    "        if i == nr_examples:\n",
    "            break\n",
    "            \n",
    "        print(character + \": \" + str(four_digits_jpg(i + 1)))\n",
    "        \n",
    "        img = cv.imread(files[i])\n",
    "        \n",
    "        num_rows = img.shape[0]\n",
    "        num_cols = img.shape[1]\n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "        \n",
    "        for j in range(num_negative_per_image):\n",
    "            x, y = find_neg_example(list_of_faces, files, min(len(files), nr_examples), i)\n",
    "\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "\n",
    "        for idx in range(len(Y)):\n",
    "            patch = img[Y[idx] : Y[idx] + box_size, X[idx] : X[idx] + box_size]\n",
    "            negative_descriptors.append(patch)\n",
    "\n",
    "    negative_descriptors = np.array(negative_descriptors)\n",
    "    return negative_descriptors\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a87313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading or generating positive training data\n",
    "if do_we_train_the_model:\n",
    "    if os.path.exists(dataset_save_path + \"/valid_faces.npy\"):\n",
    "\n",
    "        valid_faces = np.load(dataset_save_path + \"/valid_faces.npy\")\n",
    "        valid_faces_character = np.load(dataset_save_path + \"/valid_faces_character.npy\")\n",
    "\n",
    "        print('Am incarcat datele de test pozitive')\n",
    "\n",
    "    else:\n",
    "        valid_faces = get_faces(\"/andy\", nr_examples, dataset_andy_path, dataset_andy_truth_path)\n",
    "        valid_faces = np.concatenate((valid_faces, get_faces(\"/louie\", nr_examples, dataset_louie_path, dataset_louie_truth_path)))\n",
    "        valid_faces = np.concatenate((valid_faces, get_faces(\"/ora\", nr_examples, dataset_ora_path, dataset_ora_truth_path)))\n",
    "        valid_faces = np.concatenate((valid_faces, get_faces(\"/tommy\", nr_examples, dataset_tommy_path, dataset_tommy_truth_path)))\n",
    "        np.save(dataset_save_path + \"/valid_faces.npy\", valid_faces)\n",
    "        np.save(dataset_save_path + \"/valid_faces_character\", valid_faces_character)\n",
    "\n",
    "    #Loading or generating negative training data\n",
    "    if os.path.exists(dataset_save_path + \"/invalid_faces.npy\"):\n",
    "\n",
    "        invalid_faces = np.load(dataset_save_path + \"/invalid_faces.npy\")\n",
    "        print('Am incarcat datele de test negative')\n",
    "\n",
    "    else:\n",
    "        invalid_faces = get_non_faces(\"/andy\", nr_examples, nr_negatives, dataset_andy_path, dataset_andy_truth_path)\n",
    "        invalid_faces = np.concatenate((invalid_faces, get_non_faces(\"/louie\", nr_examples, nr_negatives, dataset_louie_path, dataset_louie_truth_path)))\n",
    "        invalid_faces = np.concatenate((invalid_faces, get_non_faces(\"/ora\", nr_examples, nr_negatives, dataset_ora_path, dataset_ora_truth_path)))\n",
    "        invalid_faces = np.concatenate((invalid_faces, get_non_faces(\"/tommy\", nr_examples, nr_negatives, dataset_tommy_path, dataset_tommy_truth_path)))\n",
    "        np.save(dataset_save_path + \"/invalid_faces.npy\", invalid_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50ee212",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_we_train_the_model:\n",
    "    #Priting shapes for debug\n",
    "    print(valid_faces[0].shape)\n",
    "    print(invalid_faces[0].shape)\n",
    "\n",
    "    #Merging the positive and negative examples into a dataset\n",
    "    training_examples = np.concatenate((valid_faces, invalid_faces))\n",
    "    training_labels = np.concatenate((np.array([np.array(1) for x in range(len(valid_faces))]), \\\n",
    "                                  (np.array([np.array(0) for x in range(len(invalid_faces))]))))\n",
    "\n",
    "    #Printing final data shapes for debug\n",
    "    print(training_examples.shape, training_labels.shape)\n",
    "    print(valid_faces_character[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6712f899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelul a fost incarcat! Este modelul de la ./model_91.73\n"
     ]
    }
   ],
   "source": [
    "#The structure of the convolutional neural network\n",
    "\n",
    "if from_saved_model:\n",
    "    model = keras.models.load_model(saved_model_path)\n",
    "    print(f\"Modelul a fost incarcat! Este modelul de la {saved_model_path}\")\n",
    "else:\n",
    "    if not do_we_train_the_model:\n",
    "        print(\"Nu exista nici model salvat si nici nu vrem sa antrenam, contradictie!\")\n",
    "    else:\n",
    "        print(\"Modelul va fi antrenat!\")\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(filters = 32, kernel_size = (2, 2), activation = 'relu', input_shape = (box_size, box_size, 3)),\n",
    "            keras.layers.MaxPooling2D(),\n",
    "\n",
    "            keras.layers.Conv2D(filters = 64, kernel_size = (2, 2), activation = 'relu'),\n",
    "            keras.layers.MaxPooling2D(),\n",
    "\n",
    "            keras.layers.Conv2D(filters = 128, kernel_size = (2, 2), activation = 'relu'),\n",
    "            keras.layers.MaxPooling2D(),\n",
    "\n",
    "            keras.layers.Flatten(),\n",
    "\n",
    "            keras.layers.Dense(256, activation = 'relu'),\n",
    "            keras.layers.Dropout(0.25),\n",
    "\n",
    "            keras.layers.Dense(64, activation = 'relu'),\n",
    "            keras.layers.Dropout(0.25),\n",
    "\n",
    "            keras.layers.Dense(32, activation = 'relu'),\n",
    "            keras.layers.Dropout(0.25),\n",
    "\n",
    "            keras.layers.Dense(16, activation = 'relu'),\n",
    "\n",
    "            keras.layers.Dense(2, activation = 'softmax')\n",
    "        ])\n",
    "\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate = 1e-4) \n",
    "        model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "        model.fit(training_examples, training_labels, epochs = 10,shuffle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad949a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell used to save the model if it results in a best result!\n",
    "#model.save('./model_91.73')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ecf9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions imported from Laborator9+10\n",
    "\n",
    "def intersection_over_union(bbox_a, bbox_b):\n",
    "    x_a = max(bbox_a[0], bbox_b[0])\n",
    "    y_a = max(bbox_a[1], bbox_b[1])\n",
    "    x_b = min(bbox_a[2], bbox_b[2])\n",
    "    y_b = min(bbox_a[3], bbox_b[3])\n",
    "\n",
    "    inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "\n",
    "    box_a_area = (bbox_a[2] - bbox_a[0] + 1) * (bbox_a[3] - bbox_a[1] + 1)\n",
    "    box_b_area = (bbox_b[2] - bbox_b[0] + 1) * (bbox_b[3] - bbox_b[1] + 1)\n",
    "\n",
    "    iou = inter_area / float(box_a_area + box_b_area - inter_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def compute_average_precision(rec, prec):\n",
    "    # functie adaptata din 2010 Pascal VOC development kit\n",
    "    m_rec = np.concatenate(([0], rec, [1]))\n",
    "    m_pre = np.concatenate(([0], prec, [0]))\n",
    "    for i in range(len(m_pre) - 1, -1, 1):\n",
    "        m_pre[i] = max(m_pre[i], m_pre[i + 1])\n",
    "    m_rec = np.array(m_rec)\n",
    "    i = np.where(m_rec[1:] != m_rec[:-1])[0] + 1\n",
    "    average_precision = np.sum((m_rec[i] - m_rec[i - 1]) * m_pre[i])\n",
    "    return average_precision\n",
    "\n",
    "def non_maximal_suppression(image_detections, image_scores, image_size):\n",
    "    # xmin, ymin, xmax, ymax\n",
    "    x_out_of_bounds = np.where(image_detections[:, 2] > image_size[1])[0]\n",
    "    y_out_of_bounds = np.where(image_detections[:, 3] > image_size[0])[0]\n",
    "    print(x_out_of_bounds, y_out_of_bounds)\n",
    "    image_detections[x_out_of_bounds, 2] = image_size[1]\n",
    "    image_detections[y_out_of_bounds, 3] = image_size[0]\n",
    "    sorted_indices = np.flipud(np.argsort(image_scores))\n",
    "    sorted_image_detections = image_detections[sorted_indices]\n",
    "    sorted_scores = image_scores[sorted_indices]\n",
    "\n",
    "    is_maximal = np.ones(len(image_detections)).astype(bool)\n",
    "    iou_threshold = 0.3\n",
    "    for i in range(len(sorted_image_detections) - 1):\n",
    "        if is_maximal[i] == True:  # don't change to 'is True' because is a numpy True and is not a python True :)\n",
    "            for j in range(i + 1, len(sorted_image_detections)):\n",
    "                if is_maximal[j] == True:  # don't change to 'is True' because is a numpy True and is not a python True :)\n",
    "                    if intersection_over_union(sorted_image_detections[i],sorted_image_detections[j]) > iou_threshold:is_maximal[j] = False\n",
    "                    else:  # verificam daca centrul detectiei este in mijlocul detectiei cu scor mai mare\n",
    "                        c_x = (sorted_image_detections[j][0] + sorted_image_detections[j][2]) / 2\n",
    "                        c_y = (sorted_image_detections[j][1] + sorted_image_detections[j][3]) / 2\n",
    "                        if sorted_image_detections[i][0] <= c_x <= sorted_image_detections[i][2] and \\\n",
    "                                sorted_image_detections[i][1] <= c_y <= sorted_image_detections[i][3]:\n",
    "                            is_maximal[j] = False\n",
    "    return sorted_image_detections[is_maximal], sorted_scores[is_maximal]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd03e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_detector(test_path):\n",
    "    test_path += \"/*.jpg\"\n",
    "    test_files = glob.glob(test_path)\n",
    "    detections = []\n",
    "    detection_scores = []\n",
    "    file_names = []\n",
    "\n",
    "    for ii in range(len(test_files)):\n",
    "        start_time = timeit.default_timer()\n",
    "        patches = []\n",
    "        squares = []\n",
    "        img = cv.imread(test_files[ii])\n",
    "\n",
    "        #We get diverse size patches, resize them to box_size x box_size and adding them to the predict array\n",
    "        for saiz in range(132, 24,-9):\n",
    "            for i in range(0, img.shape[0] - saiz, 4):\n",
    "                for j in range(0, img.shape[1] - saiz, 4):\n",
    "\n",
    "                    patch = img[i : i + saiz, j : j + saiz, :]\n",
    "                    patch = cv.resize(patch,(box_size, box_size), interpolation = cv.INTER_AREA)\n",
    "\n",
    "                    patches.append(patch)\n",
    "                    squares.append([j, i, j + saiz, i + saiz])\n",
    "\n",
    "        patches = np.array(patches)\n",
    "        print(test_files[ii][-8:])\n",
    "\n",
    "        model_predictions = model.predict(patches)\n",
    "\n",
    "        predictions = []\n",
    "        scores = []\n",
    "\n",
    "        #If the score between 0 and 1 received from the photo is greater than 0.8, we consider it good\n",
    "        threshold = 0.8\n",
    "        for i in range(len(patches)):\n",
    "            if model_predictions[i][1] > threshold:\n",
    "                predictions.append(squares[i])\n",
    "                scores.append(model_predictions[i][1])\n",
    "\n",
    "        nr_preds = len(predictions)\n",
    "        if nr_preds == 0:\n",
    "            continue\n",
    "\n",
    "        predictions, scores = non_maximal_suppression(np.array(predictions), np.array(scores), img.shape)\n",
    "\n",
    "        print(f\"Am extras {len(scores)} predictii din poza {test_files[ii][-8:]}\")\n",
    "\n",
    "        for i in range(len(predictions)):\n",
    "            file_names.append(test_files[ii][-8:])\n",
    "            detections.append(predictions[i])\n",
    "            detection_scores.append(scores[i])\n",
    "        end_time = timeit.default_timer()\n",
    "        print(f\"Imaginea {test_files[ii][-8:]} s-a procesat in {end_time - start_time}\")\n",
    "\n",
    "\n",
    "    return detections, detection_scores, file_names     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c72aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating predictions on the test dataset\n",
    "detections, scores, file_names = facial_detector(dataset_test_path)\n",
    "\n",
    "#If the algorithm ran on the dataset at least once, we can use the saved data instead of running it again!\n",
    "#Decomment the below lines and comment the first (without counting the comment )\n",
    "# detections = np.load(\"./data/detections_all_faces.npy\")\n",
    "# scores = np.load(\"./data/scores_all_faces.npy\")\n",
    "# file_names = np.load(\"./data/file_names_all_faces.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3869a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines that save the generated predictions to the respective paths\n",
    "np.save(task1_predictions_save_path + \"/detections_all_faces.npy\", detections)\n",
    "np.save(task1_predictions_save_path + \"/scores_all_faces.npy\", scores)\n",
    "np.save(task1_predictions_save_path + \"/file_names_all_faces.npy\", file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b39105",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea1b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_we_train_the_model:\n",
    "    #Generating the dataset\n",
    "    task2_andy_training_examples = []\n",
    "    task2_andy_training_labels = []\n",
    "    task2_louie_training_examples = []\n",
    "    task2_louie_training_labels = []\n",
    "    task2_ora_training_examples = []\n",
    "    task2_ora_training_labels = []\n",
    "    task2_tommy_training_examples = []\n",
    "    task2_tommy_training_labels = []\n",
    "\n",
    "    for i in range(len(valid_faces)):\n",
    "        # If we have a photo of character X in dataset, it will represent a positive example for \n",
    "        # the respective character classifier and a negative one for the other classifiers\n",
    "        if valid_faces_character[i] == \"andy\":\n",
    "\n",
    "            task2_andy_training_examples.append(valid_faces[i])\n",
    "            task2_andy_training_labels.append(0)\n",
    "\n",
    "            task2_louie_training_examples.append(valid_faces[i])\n",
    "            task2_louie_training_labels.append(1)\n",
    "            task2_ora_training_examples.append(valid_faces[i])\n",
    "            task2_ora_training_labels.append(1)\n",
    "            task2_tommy_training_examples.append(valid_faces[i])\n",
    "            task2_tommy_training_labels.append(1)\n",
    "\n",
    "        if valid_faces_character[i] == \"louie\":\n",
    "\n",
    "            task2_louie_training_examples.append(valid_faces[i])\n",
    "            task2_louie_training_labels.append(0)\n",
    "\n",
    "            task2_andy_training_examples.append(valid_faces[i])\n",
    "            task2_andy_training_labels.append(1)\n",
    "            task2_ora_training_examples.append(valid_faces[i])\n",
    "            task2_ora_training_labels.append(1)\n",
    "            task2_tommy_training_examples.append(valid_faces[i])\n",
    "            task2_tommy_training_labels.append(1)\n",
    "        if valid_faces_character[i] == \"ora\":\n",
    "\n",
    "            task2_ora_training_examples.append(valid_faces[i])\n",
    "            task2_ora_training_labels.append(0)\n",
    "\n",
    "            task2_louie_training_examples.append(valid_faces[i])\n",
    "            task2_louie_training_labels.append(1)\n",
    "            task2_andy_training_examples.append(valid_faces[i])\n",
    "            task2_andy_training_labels.append(1)\n",
    "            task2_tommy_training_examples.append(valid_faces[i])\n",
    "            task2_tommy_training_labels.append(1)\n",
    "        if valid_faces_character[i] == \"tommy\":\n",
    "\n",
    "            task2_tommy_training_examples.append(valid_faces[i])\n",
    "            task2_tommy_training_labels.append(0)\n",
    "\n",
    "            task2_louie_training_examples.append(valid_faces[i])\n",
    "            task2_louie_training_labels.append(1)\n",
    "            task2_ora_training_examples.append(valid_faces[i])\n",
    "            task2_ora_training_labels.append(1)\n",
    "            task2_andy_training_examples.append(valid_faces[i])\n",
    "            task2_andy_training_labels.append(1)\n",
    "\n",
    "    task2_andy_training_examples = np.array(task2_andy_training_examples)\n",
    "    task2_andy_training_labels = np.array(task2_andy_training_labels)\n",
    "    task2_louie_training_examples = np.array(task2_louie_training_examples)\n",
    "    task2_louie_training_labels = np.array(task2_louie_training_labels)\n",
    "    task2_ora_training_examples = np.array(task2_ora_training_examples)\n",
    "    task2_ora_training_labels = np.array(task2_ora_training_labels)\n",
    "    task2_tommy_training_examples = np.array(task2_tommy_training_examples)\n",
    "    task2_tommy_training_labels = np.array(task2_tommy_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf892fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am incarcat modelul pentru Andy\n",
      "Am incarcat modelul pentru Louie\n",
      "Am incarcat modelul pentru Ora\n",
      "Am incarcat modelul pentru Tommy\n"
     ]
    }
   ],
   "source": [
    "#For each character we train a classifier that decides whether a photo contains or does not contain that character\n",
    "\n",
    "#Andy\n",
    "if from_saved_model_task2:\n",
    "    \n",
    "    model_task2_andy = keras.models.load_model(saved_model_task2_andy_path)\n",
    "    print(\"Am incarcat modelul pentru Andy\")\n",
    "else:\n",
    "    \n",
    "    print(\"Se antreneaza modelul pentru Andy\")\n",
    "    model_task2_andy = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters = 32, kernel_size = (2, 2), activation = 'relu', input_shape = (box_size, box_size, 3)),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Conv2D(filters = 64, kernel_size = (2, 2), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Conv2D(filters = 128, kernel_size = (2, 2), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        keras.layers.Dense(256, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(64, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(32, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(16, activation = 'relu'),\n",
    "        \n",
    "        keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate = 2e-4) \n",
    "    model_task2_andy.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model_task2_andy.fit(task2_andy_training_examples, task2_andy_training_labels, epochs = 9,shuffle = 'True')\n",
    "\n",
    "#LOUIE\n",
    "if from_saved_model_task2:\n",
    "    \n",
    "    model_task2_louie = keras.models.load_model(saved_model_task2_louie_path)\n",
    "    print(\"Am incarcat modelul pentru Louie\")\n",
    "else:\n",
    "    \n",
    "    print(\"Se antreneaza modelul pentru Louie\")\n",
    "    model_task2_louie = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters = 32, kernel_size = (2, 2), activation = 'relu', input_shape = (box_size, box_size, 3)),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Conv2D(filters = 64, kernel_size = (2, 2), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Conv2D(filters = 128, kernel_size = (2, 2), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        keras.layers.Dense(256, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(64, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(32, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(16, activation = 'relu'),\n",
    "        \n",
    "        keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate = 2e-4) \n",
    "    model_task2_louie.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model_task2_louie.fit(task2_louie_training_examples, task2_louie_training_labels, epochs = 9,shuffle = 'True')\n",
    "\n",
    "#Ora model\n",
    "if from_saved_model_task2:\n",
    "    \n",
    "    model_task2_ora = keras.models.load_model(saved_model_task2_ora_path)\n",
    "    print(\"Am incarcat modelul pentru Ora\")\n",
    "else:\n",
    "    \n",
    "    print(\"Se antreneaza modelul pentru Ora\")\n",
    "    model_task2_ora = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters = 32, kernel_size = (2, 2), activation = 'relu', input_shape = (box_size, box_size, 3)),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Conv2D(filters = 64, kernel_size = (2, 2), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Conv2D(filters = 128, kernel_size = (2, 2), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        keras.layers.Dense(256, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(64, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(32, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(16, activation = 'relu'),\n",
    "        \n",
    "        keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate = 2e-4) \n",
    "    model_task2_ora.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model_task2_ora.fit(task2_ora_training_examples, task2_ora_training_labels, epochs = 9,shuffle = 'True')\n",
    "\n",
    "\n",
    "#Tommy model\n",
    "if from_saved_model_task2:\n",
    "    \n",
    "    model_task2_tommy = keras.models.load_model(saved_model_task2_tommy_path)\n",
    "    print(\"Am incarcat modelul pentru Tommy\")\n",
    "else:\n",
    "    \n",
    "    print(\"Se antreneaza modelul pentru Tommy\")\n",
    "    model_task2_tommy = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters = 32, kernel_size = (2, 2), activation = 'relu', input_shape = (box_size, box_size, 3)),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Conv2D(filters = 64, kernel_size = (2, 2), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Conv2D(filters = 128, kernel_size = (2, 2), activation = 'relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        keras.layers.Dense(256, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(64, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(32, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.25),\n",
    "\n",
    "        keras.layers.Dense(16, activation = 'relu'),\n",
    "        \n",
    "        keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate = 2e-4) \n",
    "    model_task2_tommy.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    model_task2_tommy.fit(task2_tommy_training_examples, task2_tommy_training_labels, epochs = 9,shuffle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2f6733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_andy\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_andy\\assets\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_louie\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_louie\\assets\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_ora\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_ora\\assets\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_tommy\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_tommy\\assets\n"
     ]
    }
   ],
   "source": [
    "#Cell used to save the models!\n",
    "model_task2_andy.save('./model_andy')\n",
    "model_task2_louie.save('./model_louie')\n",
    "model_task2_ora.save('./model_ora')\n",
    "model_task2_tommy.save('./model_tommy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec521a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_recognition(detections, file_names, path, path_save):\n",
    "        \n",
    "    print(f\"Analizam {len(detections)} detectii\")\n",
    "    andy_detections = []\n",
    "    andy_scores = []\n",
    "    andy_file_names = []\n",
    "\n",
    "    louie_detections = []\n",
    "    louie_scores = []\n",
    "    louie_file_names = []\n",
    "\n",
    "    ora_detections = []\n",
    "    ora_scores = []\n",
    "    ora_file_names = []\n",
    "\n",
    "    tommy_detections = []\n",
    "    tommy_scores = []\n",
    "    tommy_file_names = []\n",
    "\n",
    "\n",
    "    faces = []\n",
    "\n",
    "    #We create the list of faces from the task1 detections\n",
    "    for ii in range(len(detections)):\n",
    "        patches = []\n",
    "        squares = []\n",
    "\n",
    "        img = cv.imread(f\"{path}./{file_names[ii]}\")\n",
    "        img = img[int(detections[ii][1]) : int(detections[ii][3]), int(detections[ii][0]) : int(detections[ii][2])]\n",
    "        img = cv.resize(img, (box_size, box_size), interpolation = cv.INTER_AREA)\n",
    "        faces.append(img)\n",
    "\n",
    "\n",
    "    faces = np.array(faces)\n",
    "\n",
    "    #Predict on the list of faces(scores between 0 and 1 if in the photo is andy/louie/ora/tommy)\n",
    "    andy_predictions = model_task2_andy.predict(faces)\n",
    "    louie_predictions = model_task2_louie.predict(faces)\n",
    "    ora_predictions = model_task2_ora.predict(faces)\n",
    "    tommy_predictions = model_task2_tommy.predict(faces)\n",
    "\n",
    "    #Score threshold to consider that the photo contains the face of a character\n",
    "    threshold = 0.9\n",
    "    for i in range(len(andy_predictions)):\n",
    "        \n",
    "        #Debug info\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Suntem la detectia {i}: poza {file_names[i]} coordonatele {detections[i]}\")\n",
    "\n",
    "        img = cv.imread(f\"{path}./{file_names[i]}\")\n",
    "        img = img[int(detections[i][1]) : int(detections[i][3]), int(detections[i][0]) : int(detections[i][2])]\n",
    "\n",
    "        #Checking the score for each character if it is within the required threshold \n",
    "        if andy_predictions[i][0] >= threshold:\n",
    "            andy_detections.append(detections[i])\n",
    "            andy_scores.append(andy_predictions[i][0])\n",
    "            andy_file_names.append(file_names[i])\n",
    "            \n",
    "        if louie_predictions[i][0] >= threshold:\n",
    "            louie_detections.append(detections[i])\n",
    "            louie_scores.append(louie_predictions[i][0])\n",
    "            louie_file_names.append(file_names[i])\n",
    "            \n",
    "        if ora_predictions[i][0] >= threshold:\n",
    "            ora_detections.append(detections[i])\n",
    "            ora_scores.append(ora_predictions[i][0])\n",
    "            ora_file_names.append(file_names[i])\n",
    "            \n",
    "        if tommy_predictions[i][0] >= threshold:\n",
    "            tommy_detections.append(detections[i])\n",
    "            tommy_scores.append(tommy_predictions[i][0])\n",
    "            tommy_file_names.append(file_names[i])\n",
    "\n",
    "\n",
    "    andy_detections = np.array(andy_detections)\n",
    "    andy_scores = np.array(andy_scores)\n",
    "    andy_file_names = np.array(andy_file_names)\n",
    "\n",
    "    louie_detections = np.array(louie_detections)\n",
    "    louie_scores = np.array(louie_scores)\n",
    "    louie_file_names = np.array(louie_file_names)\n",
    "\n",
    "    ora_detections = np.array(ora_detections)\n",
    "    ora_scores = np.array(ora_scores)\n",
    "    ora_file_names = np.array(ora_file_names)\n",
    "\n",
    "    tommy_detections = np.array(tommy_detections)\n",
    "    tommy_scores = np.array(tommy_scores)\n",
    "    tommy_file_names = np.array(tommy_file_names)\n",
    "    \n",
    "    #Saving the predictions\n",
    "    np.save(path_save + \"/detections_andy.npy\", andy_detections)\n",
    "    np.save(path_save + \"/scores_andy.npy\", andy_scores)\n",
    "    np.save(path_save + \"/file_names_andy.npy\", andy_file_names)\n",
    "    \n",
    "    np.save(path_save + \"/detections_louie.npy\", louie_detections)\n",
    "    np.save(path_save + \"/scores_louie.npy\", louie_scores)\n",
    "    np.save(path_save + \"/file_names_louie.npy\", louie_file_names)\n",
    "    \n",
    "    np.save(path_save + \"/detections_ora.npy\", ora_detections)\n",
    "    np.save(path_save + \"/scores_ora.npy\", ora_scores)\n",
    "    np.save(path_save + \"/file_names_ora.npy\", ora_file_names)\n",
    "    \n",
    "    np.save(path_save + \"/detections_tommy.npy\", tommy_detections)\n",
    "    np.save(path_save + \"/scores_tommy.npy\", tommy_scores)\n",
    "    np.save(path_save + \"/file_names_tommy.npy\", tommy_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0f3c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizam 1124 detectii\n",
      "Suntem la detectia 0: poza 0001.jpg coordonatele [184 184 316 316]\n",
      "Suntem la detectia 100: poza 0020.jpg coordonatele [108 192 141 225]\n",
      "Suntem la detectia 200: poza 0037.jpg coordonatele [192 196 324 328]\n",
      "Suntem la detectia 300: poza 0059.jpg coordonatele [  4  88  37 121]\n",
      "Suntem la detectia 400: poza 0075.jpg coordonatele [236 272 269 305]\n",
      "Suntem la detectia 500: poza 0099.jpg coordonatele [ 40 136 145 241]\n",
      "Suntem la detectia 600: poza 0116.jpg coordonatele [308 288 341 321]\n",
      "Suntem la detectia 700: poza 0135.jpg coordonatele [ 32 156  83 207]\n",
      "Suntem la detectia 800: poza 0152.jpg coordonatele [416 104 449 137]\n",
      "Suntem la detectia 900: poza 0169.jpg coordonatele [ 92  72 152 132]\n",
      "Suntem la detectia 1000: poza 0183.jpg coordonatele [240 188 291 239]\n",
      "Suntem la detectia 1100: poza 0198.jpg coordonatele [192  88 306 202]\n"
     ]
    }
   ],
   "source": [
    "facial_recognition(detections, file_names, dataset_test_path, task2_predictions_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f380d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
